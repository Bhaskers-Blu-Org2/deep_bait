{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Chainer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EPOCHS = 10\n",
    "N_CLASSES=10\n",
    "BATCHSIZE = 64\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "GPU = True\n",
    "\n",
    "LOGGER_URL='msdlvm.southcentralus.cloudapp.azure.com'\n",
    "LOGGER_USRENAME='admin'\n",
    "LOGGER_PASSWORD='password'\n",
    "LOGGER_DB='gpudata'\n",
    "LOGGER_SERIES='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers\n",
    "from chainer import cuda\n",
    "from utils import cifar_for_library, yield_mb, create_logger, Timer\n",
    "from gpumon.influxdb import log_context\n",
    "\n",
    "from influxdb import InfluxDBClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient(LOGGER_URL, 8086, LOGGER_USRENAME, LOGGER_PASSWORD, LOGGER_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = os.getenv('AZ_BATCH_NODE_ID', default='node')\n",
    "task_id = os.getenv('AZ_BATCH_TASK_ID', default='chainer')\n",
    "job_id = os.getenv('AZ_BATCH_JOB_ID', default='chainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(client, node_id=node_id, task_id=task_id, job_id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Chainer: \", chainer.__version__)\n",
    "print(\"Numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = path.join(os.getenv('AZ_BATCHAI_INPUT_DATASET'), 'cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SymbolModule(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(SymbolModule, self).__init__(\n",
    "            conv1=L.Convolution2D(3, 50, ksize=(3,3), pad=(1,1)),\n",
    "            conv2=L.Convolution2D(50, 50, ksize=(3,3), pad=(1,1)),      \n",
    "            conv3=L.Convolution2D(50, 100, ksize=(3,3), pad=(1,1)),  \n",
    "            conv4=L.Convolution2D(100, 100, ksize=(3,3), pad=(1,1)),  \n",
    "            # feature map size is 8*8 by pooling\n",
    "            fc1=L.Linear(100*8*8, 512),\n",
    "            fc2=L.Linear(512, N_CLASSES),\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv2(F.relu(self.conv1(x))))\n",
    "        h = F.max_pooling_2d(h, ksize=(2,2), stride=(2,2))\n",
    "        h = F.dropout(h, 0.25)\n",
    "        \n",
    "        h = F.relu(self.conv4(F.relu(self.conv3(h))))\n",
    "        h = F.max_pooling_2d(h, ksize=(2,2), stride=(2,2))\n",
    "        h = F.dropout(h, 0.25)       \n",
    "        \n",
    "        h = F.dropout(F.relu(self.fc1(h)), 0.5)\n",
    "        return self.fc2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(m):\n",
    "    optimizer = optimizers.MomentumSGD(lr=LR, momentum=MOMENTUM)\n",
    "    optimizer.setup(m)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_chainer(array, **kwargs):\n",
    "    return chainer.Variable(cuda.to_gpu(array), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Preparing test set...\n",
      "Done.\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000,) (10000,)\n",
      "float32 float32 int32 int32\n",
      "CPU times: user 848 ms, sys: 560 ms, total: 1.41 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(data_path, channel_first=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 2.66 s, total: 1min 18s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create symbol\n",
    "sym = SymbolModule()\n",
    "if GPU:\n",
    "    chainer.cuda.get_device(0).use()  # Make a specified GPU current\n",
    "    sym.to_gpu()  # Copy the model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 119 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "CPU times: user 2min 3s, sys: 2.14 s, total: 2min 6s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    with log_context(LOGGER_URL, LOGGER_USRENAME, LOGGER_PASSWORD, LOGGER_DB, LOGGER_SERIES, \n",
    "                     node_id=node_id, task_id=task_id, job_id=job_id):\n",
    "        for j in range(EPOCHS):\n",
    "            for data, target in yield_mb(x_train, y_train, BATCHSIZE, shuffle=True):\n",
    "                # Get samples\n",
    "                optimizer.update(L.Classifier(sym), to_chainer(data), to_chainer(target))\n",
    "            # Log\n",
    "            print(j)\n",
    "print('Training took %.03f sec.' % t.interval)\n",
    "logger('training duration', value=t.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 600 ms, sys: 128 ms, total: 728 ms\n",
      "Wall time: 725 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_samples = (y_test.shape[0]//BATCHSIZE)*BATCHSIZE\n",
    "y_guess = np.zeros(n_samples, dtype=np.int)\n",
    "y_truth = y_test[:n_samples]\n",
    "c = 0\n",
    "\n",
    "with chainer.using_config('train', False):\n",
    "    for data, target in yield_mb(x_test, y_test, BATCHSIZE):\n",
    "        # Forwards\n",
    "        pred = chainer.cuda.to_cpu(sym(to_chainer(data)).data.argmax(-1))\n",
    "        # Collect results\n",
    "        y_guess[c*BATCHSIZE:(c+1)*BATCHSIZE] = pred\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.787159455128\n"
     ]
    }
   ],
   "source": [
    "acc=sum(y_guess == y_truth)/len(y_guess)\n",
    "print(\"Accuracy: \", acc)\n",
    "logger('accuracy', value=acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
